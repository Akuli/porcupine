# These settings can be overrided in your user-specific filetypes.toml. To edit
# it, go to Settings --> Config Files.
#
# There's a friendly introduction to editing this file on Porcupine Wiki:
#
#    https://github.com/Akuli/porcupine/wiki/Getting-Porcupine-to-work-with-a-programming-language
#
# Most commonly used options that Porcupine comes with (plugins may add more):
#
#    filename_patterns
#        List of strings with * used as wildcard, such as "*.py" to match files
#        named "something.py". You can also specify "foo/*.py" to only match
#        Python files inside a folder named foo, but you must use forward
#        slashes for this, even on Windows.
#
#    shebang_regex
#        Regular expression checked against the first line of a file when no
#        filename_pattern matches. See the Python documentation for supported
#        regular expression syntax:
#
#            https://docs.python.org/3/library/re.html#regular-expression-syntax
#
#        Use single quotes to avoid having to escape backslashes.
#
#        By default, the regex may match any part of the first line. Put the
#        regex between ^ and $ to match the entire first line, e.g.
#
#            '^#!/usr/bin/python(2|3)$'
#
#        Arguments starting with '-' are ignored, so the regex '^#!/bin/foo$'
#        matches the shebang '#!/bin/foo --bar --baz'.
#
#    syntax_highlighter
#        Porcupine currently comes with two syntax highlighters that this
#        setting chooses from:
#
#            "pygments"
#                This syntax highlighter supports many different languages and
#                it is easy to configure, but it is slow with large files. It
#                also has known bugs that are basically impossible to fix:
#                sometimes editing the code and reverting your edits changes how
#                the code is highlighted.
#
#                Recommended for any language with small files.
#
#            "tree_sitter"
#                A fast highlighter that produces consistent results as the code
#                is being edited. However, this highlighter supports only a few
#                languages. Several things must be done for a language to be
#                supported, and as a user of Porcupine, you probably shouldn't
#                try to configure this highlighter yourself; just ask me to do
#                it instead by making an issue on GitHub.
#
#                Recommended for languages with large files or known bugs with
#                the "pygments" highlighter.
#
#        Regardless of this setting, the color theme is always taken from
#        Pygments, because there are many Pygments themes and it is easy to get
#        them to work with other highlighting libraries. The theme can be
#        changed in Porcupine Settings (in the Settings menu).
#
#    pygments_lexer (default: "pygments.lexers.TextLexer")
#        If syntax_highlighter is set to "pygments", this should be the name of
#        a Pygments lexer class that will be used for syntax highlighting. See
#        the Pygments documentation for lexers that Pygments comes with:
#
#            https://pygments.org/docs/lexers/
#
#    tree_sitter
#        Configuration for the "tree_sitter" syntax highlighter. You can look
#        at the examples below to figure out how it works, or ask me to
#        document it better.
#
#        The tree-sitter highlighter plugin has a command-line interface for
#        exploring the structure of programs:
#
#            $ cat hello.py
#            print("hello")
#
#            $ python3 -m porcupine.plugins.tree_sitter_highlight python hello.py
#            type=module text='print("hello")\n'
#              type=expression_statement text='print("hello")'
#                type=call text='print("hello")'
#                  type=identifier text='print'
#                  type=argument_list text='("hello")'
#                    type=( text='('
#                    type=string text='"hello"'
#                      type=" text='"'
#                      type=" text='"'
#                    type=) text=')'
#
#        You can then use the output to write syntax-highlighting rules. For
#        example, a type=identifier token with text='print' should be colored as
#        a built-in function, which is why below in this file you will find:
#
#            [Python.tree_sitter.token_mapping.identifier]
#            ...
#            print = "Token.Name.Builtin"
#
#    tabs2spaces (default: true)
#        If this is true, then spaces will be used for indentation.
#
#    indent_size (default: 4)
#        If tabs2spaces is false, this specifies the number of spaces
#        corresponding to one tab character. If tabs2spaces is true, then this
#        is the number of spaces used for indentation.
#
#    autoindent_regexes
#        Regexes used to determine whether the code should be indented or
#        dedented automatically when enter is pressed. Before using these
#        regexes, comments are removed and whitespace is stripped from beginning
#        and end of the line. Then the regexes are matched against the entire
#        line so that even if the regex does not use '^' or '$', it must match
#        the entire line.
#
#            indent_regex
#                A regular expression for indenting, such as '.*:' to indent
#                when a line ends with colon.
#
#            dedent_regex
#                A regular expression for dedenting.
#
#            dedent_prev_line (default: false)
#                Whether to dedent the previous line as well.
#
#        In addition to these regular expressions, (), {} and [] are supported
#        with all file types.
#
#    comment_prefix
#        If specified as one character, typing this character with many lines
#        selected will put it to the beginning of each line. For example, for
#        making comments like the comment that you are currently reading, this
#        is set to '#' in the [TOML] section. This is also used to strip
#        comments from lines of code before using autoindent_regexes.
#
#    trim_trailing_whitespace
#        Set this to false to prevent removing whitespace from ends of the lines
#        automatically when Enter is pressed. The default is true.
#
#    insert_final_newline
#        By default, Porcupine makes sure that files end with a newline when
#        saving. Set this to false to disable that.
#
#    max_line_length
#        How many characters to put before the long line marker. Set this to 0
#        or negative value to disable the long line marker.
#
#    autocomplete_chars
#        List of one-character strings. The autocompletion popup triggers
#        automatically when one of these characters is entered.
#
#    example_commands
#        List with information about a command to show in the "Run Command"
#        dialog (Shift+{F5,F6,F7,F8} by default). Each list item must have the
#        following keys:
#
#            command
#                Content of the "Run this command" text entry.
#
#            windows_command (default: same as command)
#                If this is specified and porcupine is running on Windows, it is
#                used instead of "command".
#
#            macos_command (default: same as command)
#                If this is specified and porcupine is running on MacOS, it is
#                used instead of "command".
#
#            working_directory (default: "{folder_path}")
#                Content of the "In this directory" text entry.
#
#            external_terminal (default: true)
#                Boolean: true to use a terminal or command prompt, false to run
#                within the same Porcupine window.
#
#    langserver
#        A mapping with these keys and values in it:
#
#        command
#            Command string that will be ran to start the langserver process.
#            You can use the following substitution:
#
#            {porcupine_python}
#                Path to the Python executable that Porcupine is currently
#                running with. This is not necessarily the same Python that is
#                used for running programs written by the user. For example, on
#                Windows, the Porcupine installer includes a copy of Python,
#                and {porcupine_python} points to that.
#
#            The command string is first split into parts and then substituted,
#            so you likely don't need to worry about quoting or escaping.
#
#        language_id
#            An "Identifier" from the table shown here, as a string:
#            https://microsoft.github.io/language-server-protocol/specifications/specification-current/#textDocumentItem
#
#        port
#            Leave this unset if you want to use stdin and stdout with the
#            langserver. If the langserver uses a TCP socket listening on
#            localhost instead, then set this to the port number that it uses.
#
#        settings
#            Configuration that will be passed to the langserver, as a nested
#            mapping. See the langserver's for what you can include here.
#
#            In strings, {python_venv} will be replaced with a path to the
#            currently selected Python virtual environment. If no venv is set,
#            the whole string will be replaced with null.

["Plain Text"]
filename_patterns = ["*.txt"]
pygments_lexer = "pygments.lexers.TextLexer"

[Python]
filename_patterns = ["*.py", "*.pyw"]
shebang_regex = 'python(\d(\.\d)?)?$'
pygments_lexer = "pygments.lexers.Python3Lexer"
tabs2spaces = true
indent_size = 4
max_line_length = 79   # pep8 says so, lol
comment_prefix = '#'
autoindent_regexes = {dedent = '(return|raise)( .+)?|break|pass|continue', indent = '.*:'}
[[Python.example_commands]]
command = "python3 {file_name}"
windows_command = "py {file_name}"
[[Python.example_commands]]
command = "python3 -m {project_name}"
windows_command = "py -m {project_name}"
working_directory = "{project_path}"
[Python.langserver]
command = "{porcupine_python} -m pyls"
language_id = "python"
[Python.langserver.settings.pyls.plugins.jedi]
environment = "{python_venv}"
[Python.tree_sitter]
language_name = "python"
# TODO: distinguish between variables and attributes?
# Can't just add "attribute" to dont_recurse_inside because then the object
# whose attribute it is won't highlight, e.g. open("foo", "rb").read()
#
# TODO: recurse inside f-strings
dont_recurse_inside = ["string"]
[Python.tree_sitter.token_mapping]
comment = "Token.Comment"
# TODO: which of the number things are needed?
integer = "Token.Literal.Number.Integer"
float = "Token.Literal.Number.Float"
string = "Token.Literal.String"
and = "Token.Keyword"
as = "Token.Keyword"
assert = "Token.Keyword"
async = "Token.Keyword"
await = "Token.Keyword"
break = "Token.Keyword"
class = "Token.Keyword"
continue = "Token.Keyword"
def = "Token.Keyword"
del = "Token.Keyword"
elif = "Token.Keyword"
else = "Token.Keyword"
except = "Token.Keyword"
false = "Token.Keyword"
finally = "Token.Keyword"
for = "Token.Keyword"
from = "Token.Keyword"
global = "Token.Keyword"
if = "Token.Keyword"
import = "Token.Keyword"
in = "Token.Keyword"
is = "Token.Keyword"
lambda = "Token.Keyword"
none = "Token.Keyword"
nonlocal = "Token.Keyword"
not = "Token.Keyword"
or = "Token.Keyword"
pass = "Token.Keyword"
raise = "Token.Keyword"
return = "Token.Keyword"
true = "Token.Keyword"
try = "Token.Keyword"
while = "Token.Keyword"
with = "Token.Keyword"
yield = "Token.Keyword"
[Python.tree_sitter.token_mapping.identifier]
ArithmeticError = "Token.Name.Exception"
AssertionError = "Token.Name.Exception"
AttributeError = "Token.Name.Exception"
BaseException = "Token.Name.Builtin"
BlockingIOError = "Token.Name.Exception"
BrokenPipeError = "Token.Name.Exception"
BufferError = "Token.Name.Exception"
BytesWarning = "Token.Name.Builtin"
ChildProcessError = "Token.Name.Exception"
ConnectionAbortedError = "Token.Name.Exception"
ConnectionError = "Token.Name.Exception"
ConnectionRefusedError = "Token.Name.Exception"
ConnectionResetError = "Token.Name.Exception"
DeprecationWarning = "Token.Name.Builtin"
EOFError = "Token.Name.Exception"
Ellipsis = "Token.Name.Builtin"
EnvironmentError = "Token.Name.Exception"
Exception = "Token.Name.Builtin"
False = "Token.Name.Builtin"
FileExistsError = "Token.Name.Exception"
FileNotFoundError = "Token.Name.Exception"
FloatingPointError = "Token.Name.Exception"
FutureWarning = "Token.Name.Builtin"
GeneratorExit = "Token.Name.Builtin"
IOError = "Token.Name.Exception"
ImportError = "Token.Name.Exception"
ImportWarning = "Token.Name.Builtin"
IndentationError = "Token.Name.Exception"
IndexError = "Token.Name.Exception"
InterruptedError = "Token.Name.Exception"
IsADirectoryError = "Token.Name.Exception"
KeyError = "Token.Name.Exception"
KeyboardInterrupt = "Token.Name.Builtin"
LookupError = "Token.Name.Exception"
MemoryError = "Token.Name.Exception"
ModuleNotFoundError = "Token.Name.Exception"
NameError = "Token.Name.Exception"
None = "Token.Name.Builtin"
NotADirectoryError = "Token.Name.Exception"
NotImplemented = "Token.Name.Builtin"
NotImplementedError = "Token.Name.Exception"
OSError = "Token.Name.Exception"
OverflowError = "Token.Name.Exception"
PendingDeprecationWarning = "Token.Name.Builtin"
PermissionError = "Token.Name.Exception"
ProcessLookupError = "Token.Name.Exception"
RecursionError = "Token.Name.Exception"
ReferenceError = "Token.Name.Exception"
ResourceWarning = "Token.Name.Builtin"
RuntimeError = "Token.Name.Exception"
RuntimeWarning = "Token.Name.Builtin"
StopAsyncIteration = "Token.Name.Builtin"
StopIteration = "Token.Name.Builtin"
SyntaxError = "Token.Name.Exception"
SyntaxWarning = "Token.Name.Builtin"
SystemError = "Token.Name.Exception"
SystemExit = "Token.Name.Builtin"
TabError = "Token.Name.Exception"
TimeoutError = "Token.Name.Exception"
True = "Token.Name.Builtin"
TypeError = "Token.Name.Exception"
UnboundLocalError = "Token.Name.Exception"
UnicodeDecodeError = "Token.Name.Exception"
UnicodeEncodeError = "Token.Name.Exception"
UnicodeError = "Token.Name.Exception"
UnicodeTranslateError = "Token.Name.Exception"
UnicodeWarning = "Token.Name.Builtin"
UserWarning = "Token.Name.Builtin"
ValueError = "Token.Name.Exception"
Warning = "Token.Name.Builtin"
ZeroDivisionError = "Token.Name.Exception"
__debug__ = "Token.Name.Builtin"
__doc__ = "Token.Name.Builtin"
__import__ = "Token.Name.Builtin"
__loader__ = "Token.Name.Builtin"
__name__ = "Token.Name.Builtin"
__package__ = "Token.Name.Builtin"
__path__ = "Token.Name.Builtin"
__spec__ = "Token.Name.Builtin"
abs = "Token.Name.Builtin"
all = "Token.Name.Builtin"
any = "Token.Name.Builtin"
ascii = "Token.Name.Builtin"
bin = "Token.Name.Builtin"
bool = "Token.Name.Builtin"
breakpoint = "Token.Name.Builtin"
bytearray = "Token.Name.Builtin"
bytes = "Token.Name.Builtin"
callable = "Token.Name.Builtin"
chr = "Token.Name.Builtin"
classmethod = "Token.Name.Builtin"
compile = "Token.Name.Builtin"
complex = "Token.Name.Builtin"
copyright = "Token.Name.Builtin"
credits = "Token.Name.Builtin"
delattr = "Token.Name.Builtin"
dict = "Token.Name.Builtin"
dir = "Token.Name.Builtin"
divmod = "Token.Name.Builtin"
enumerate = "Token.Name.Builtin"
eval = "Token.Name.Builtin"
exec = "Token.Name.Builtin"
exit = "Token.Name.Builtin"
filter = "Token.Name.Builtin"
float = "Token.Name.Builtin"
format = "Token.Name.Builtin"
frozenset = "Token.Name.Builtin"
getattr = "Token.Name.Builtin"
globals = "Token.Name.Builtin"
hasattr = "Token.Name.Builtin"
hash = "Token.Name.Builtin"
help = "Token.Name.Builtin"
hex = "Token.Name.Builtin"
id = "Token.Name.Builtin"
input = "Token.Name.Builtin"
int = "Token.Name.Builtin"
isinstance = "Token.Name.Builtin"
issubclass = "Token.Name.Builtin"
iter = "Token.Name.Builtin"
len = "Token.Name.Builtin"
license = "Token.Name.Builtin"
list = "Token.Name.Builtin"
locals = "Token.Name.Builtin"
map = "Token.Name.Builtin"
max = "Token.Name.Builtin"
memoryview = "Token.Name.Builtin"
min = "Token.Name.Builtin"
next = "Token.Name.Builtin"
object = "Token.Name.Builtin"
oct = "Token.Name.Builtin"
open = "Token.Name.Builtin"
ord = "Token.Name.Builtin"
pow = "Token.Name.Builtin"
print = "Token.Name.Builtin"
property = "Token.Name.Builtin"
quit = "Token.Name.Builtin"
range = "Token.Name.Builtin"
repr = "Token.Name.Builtin"
reversed = "Token.Name.Builtin"
round = "Token.Name.Builtin"
self = "Token.Name.Builtin"
set = "Token.Name.Builtin"
setattr = "Token.Name.Builtin"
slice = "Token.Name.Builtin"
sorted = "Token.Name.Builtin"
staticmethod = "Token.Name.Builtin"
str = "Token.Name.Builtin"
sum = "Token.Name.Builtin"
super = "Token.Name.Builtin"
tuple = "Token.Name.Builtin"
type = "Token.Name.Builtin"
vars = "Token.Name.Builtin"
zip = "Token.Name.Builtin"

["Python stub file"]
filename_patterns = ["*.pyi"]
pygments_lexer = "pygments.lexers.Python3Lexer"
tabs2spaces = true
indent_size = 4
max_line_length = 130   # https://github.com/python/typeshed/blob/4586ed9/CONTRIBUTING.md#conventions
autocomplete_chars = ["."]
comment_prefix = '#'
autoindent_regexes = {indent = '.*:'}

[C]
filename_patterns = ["*.c", "*.h"]
pygments_lexer = "pygments.lexers.CLexer"
comment_prefix = '//'
# Press alt+enter instead of enter to avoid indent after 'case foo:'
autoindent_regexes = {dedent = '(return( .+)?|break|continue);', indent = '(case .+|default):'}

["C++"]
# Override this in your own filetypes.toml if you use .h for C++ headers
filename_patterns = ["*.c++", "*.cpp", "*.cxx", "*.cc", "*.h++", "*.hpp", "*.hxx", "*.hh"]
pygments_lexer = "pygments.lexers.CppLexer"
comment_prefix = '//'
autoindent_regexes = {dedent = '(throw .+|return( .+)?|break|continue);', indent = '(case .+|default):'}

[[C.example_commands]]
command = "gcc {file_name} -Wall -Wextra -std=c99 -o {file_stem}"
windows_command = "gcc {file_name} -Wall -Wextra -std=c99 -o {file_stem}.exe"
external_terminal = false
[["C++".example_commands]]
command = "g++ {file_name} -Wall -Wextra -std=c++17 -o {file_stem}"
windows_command = "g++ {file_name} -Wall -Wextra -std=c++17 -o {file_stem}.exe"
external_terminal = false

[[C.example_commands]]
command = "./{file_stem}"
windows_command = "{file_stem}.exe"
[["C++".example_commands]]
command = "./{file_stem}"
windows_command = "{file_stem}.exe"

[C.langserver]
command = "clangd"
language_id = "c"
["C++".langserver]
command = "clangd"
language_id = "cpp"

[Java]
filename_patterns = ["*.java"]
pygments_lexer = "pygments.lexers.JavaLexer"
comment_prefix = '//'
autoindent_regexes = {dedent = '(throw .+|return( .+)?|break|continue);', indent = '(case .+|default):'}

[[Java.example_commands]]
command = "javac {file_name}"
external_terminal = false
[[Java.example_commands]]
command = "java {file_stem}"

[JavaScript]
filename_patterns = ["*.js"]
pygments_lexer = "pygments.lexers.JavascriptLexer"
tabs2spaces = true
indent_size = 2
comment_prefix = '//'
autoindent_regexes = {dedent = '(throw .+|return( .+)?|break|continue);', indent = '(case .+|default):'}
# TODO: node typically ends up in path from ~/.bashrc
[[JavaScript.example_commands]]
command = "node {file_name}"
external_terminal = false  # useful for webdev?

[TypeScript]
filename_patterns = ["*.ts"]
pygments_lexer = "pygments.lexers.TypeScriptLexer"
tabs2spaces = true
indent_size = 2
comment_prefix = '//'
autoindent_regexes = {dedent = '(throw .+|return( .+)?|break|continue);', indent = '(case .+|default):'}
[[TypeScript.example_commands]]
command = "tsc {file_name}"
external_terminal = false
[[TypeScript.example_commands]]
command = "node {file_stem}.js"
external_terminal = false  # useful for webdev?

[Makefile]
filename_patterns = ["Makefile", "makefile", "Makefile.*", "makefile.*"]
pygments_lexer = "pygments.lexers.MakefileLexer"
# make doesn't work with spaces
tabs2spaces = false
comment_prefix = '#'
[[Makefile.example_commands]]
command = "make"
working_directory = "{project_path}"
external_terminal = false

# TODO: Windows batch files and powershell files
# override pygments_lexer if you want to
# shebang_regex is partly copy/pasted from nano's default config
[Shell]
filename_patterns = ["*.sh"]
shebang_regex = '((ba|da|k|pdk)?sh[-0-9_]*|openrc-run|runscript)$'
pygments_lexer = "pygments.lexers.BashLexer"
comment_prefix = '#'
autoindent_regexes = {dedent = '(return|exit)( .+)?|break|continue|;;', indent = '[^()]+\)|.*\b(then|do|else|in)'}
[[Shell.example_commands]]
command = "./{file_name}"
[[Shell.example_commands]]
command = "shellcheck {file_name}"
external_terminal = false

# tcl man pages and many people on wiki.tcl.tk indent with 3 spaces
[Tcl]
filename_patterns = ["*.tcl"]
shebang_regex = '(wi|tcl)sh$'
pygments_lexer = "pygments.lexers.TclLexer"
tabs2spaces = true
comment_prefix = '#'
[[Tcl.example_commands]]
command = "tclsh {file_name}"

# TODO: autoindents for many more languages

[JSON]
filename_patterns = ["*.json"]
pygments_lexer = "pygments.lexers.JsonLexer"
indent_size = 2
tabs2spaces = true

[TOML]
filename_patterns = ["*.toml"]
pygments_lexer = "pygments.lexers.TOMLLexer"
comment_prefix = '#'
[TOML.tree_sitter]
language_name = "toml"
dont_recurse_inside = ["quoted_key", "string", "dotted_key"]
[TOML.tree_sitter.token_mapping]
# see hacky code in the plugin
table = "Token.Keyword"
table_array_element = "Token.Keyword"
comment = "Token.Comment"
# TODO: which of the number things are needed?
boolean = "Token.Keyword"
quoted_key = "Token.Literal.String"
integer = "Token.Literal.Number.Integer"
float = "Token.Literal.Number.Float"
string = "Token.Literal.String"

[reStructuredText]
filename_patterns = ["*.rst"]
pygments_lexer = "pygments.lexers.RstLexer"

[Markdown]
filename_patterns = ["*.md", "*.markdown"]
pygments_lexer = "pygments.lexers.MarkdownLexer"
autoindent_regexes = {dedent = '.*\.', indent = '^([0-9]+\.|-) .*'}

[YAML]
filename_patterns = ["*.yml", "*.yaml"]
pygments_lexer = "pygments.lexers.YamlLexer"
tabs2spaces = true
indent_size = 2
comment_prefix = '#'
autoindent_regexes = {indent = '.*:'}

[HTML]
filename_patterns = ["*.html", "*.htm"]
pygments_lexer = "pygments.lexers.HtmlLexer"
tabs2spaces = true
indent_size = 2
autoindent_regexes = {dedent = '</.*>', indent = '<[^/!][^<>]*[^/]>|<[A-Za-z]>', dedent_prev_line = true}

[[HTML.example_commands]]
command = "x-www-browser {file_path} >/dev/null 2>&1 &"
macos_command = "open {file_path} >/dev/null 2>&1 &"
windows_command = "explorer {file_path}"
external_terminal = false

[TeX]
filename_patterns = ["*.tex"]
pygments_lexer = "pygments.lexers.TexLexer"
tabs2spaces = true
comment_prefix = '%'

["NSIS installer file"]
filename_patterns = ["*.nsi", "*.nsh"]
pygments_lexer = "pygments.lexers.NSISLexer"
tabs2spaces = true
indent_size = 2
comment_prefix = ';'

[Rust]
filename_patterns = ["*.rs"]
pygments_lexer = "pygments.lexers.RustLexer"
tabs2spaces = true
indent_size = 4
comment_prefix = '//'
autoindent_regexes = {dedent = '(return( .+)?|break|continue);', indent = 'this regex matches nothing^'}
[Rust.tree_sitter]
language_name = "rust"
# recursing inside scoped_identifier would break highlighting of tokio::select!
# TODO: Vec::foo() doesn't highlight properly
dont_recurse_inside = ["string", "attribute", "scoped_identifier", "string_literal", "attribute_item"]
[Rust.tree_sitter.token_mapping]
line_comment = "Token.Comment"
block_comment = "Token.Comment"
integer_literal = "Token.Literal.Number.Integer"
float_literal = "Token.Literal.Number.Float"
string_literal = "Token.Literal.String"
raw_string_literal = "Token.Literal.String"
char_literal = "Token.Literal.String"
self = "Token.Name.Builtin"  # special-cased in compiler, but doesn't feel like a keyword
pub = "Token.Keyword"
async = "Token.Keyword"
fn = "Token.Keyword"
as = "Token.Keyword"
in = "Token.Keyword"
for = "Token.Keyword"
while = "Token.Keyword"
loop = "Token.Keyword"
let = "Token.Keyword"
mutable_specifier = "Token.Keyword"  # the "mut" keyword
match = "Token.Keyword"
break = "Token.Keyword"
continue = "Token.Keyword"
const = "Token.Keyword"
return = "Token.Keyword"
if = "Token.Keyword"
else = "Token.Keyword"
struct = "Token.Keyword"
impl = "Token.Keyword"
type = "Token.Keyword"
enum = "Token.Keyword"
trait = "Token.Keyword"
dyn = "Token.Keyword"
where = "Token.Keyword"
use = "Token.Keyword"
mod = "Token.Keyword"
crate = "Token.Keyword"
attribute_item = "Token.Name.Decorator"  # lol
macro_invocation = "Token.Name.Decorator"  # lol
primitive_type = "Token.Keyword"
true = "Token.Keyword"
false = "Token.Keyword"
# builtins taken from pygments
[Rust.tree_sitter.token_mapping.type_identifier]
Send = "Token.Name.Builtin"
Sized = "Token.Name.Builtin"
Sync = "Token.Name.Builtin"
Unpin = "Token.Name.Builtin"
Drop = "Token.Name.Builtin"
Fn = "Token.Name.Builtin"
FnMut = "Token.Name.Builtin"
FnOnce = "Token.Name.Builtin"
AsRef = "Token.Name.Builtin"
AsMut = "Token.Name.Builtin"
Into = "Token.Name.Builtin"
From = "Token.Name.Builtin"
Iterator = "Token.Name.Builtin"
Extend = "Token.Name.Builtin"
IntoIterator = "Token.Name.Builtin"
DoubleEndedIterator = "Token.Name.Builtin"
ExactSizeIterator = "Token.Name.Builtin"
Option = "Token.Name.Builtin"
Result = "Token.Name.Builtin"
Box = "Token.Name.Builtin"
ToOwned = "Token.Name.Builtin"
String = "Token.Name.Builtin"
ToString = "Token.Name.Builtin"
Vec = "Token.Name.Builtin"
Clone = "Token.Name.Builtin"
Copy = "Token.Name.Builtin"
Default = "Token.Name.Builtin"
Eq = "Token.Name.Builtin"
Hash = "Token.Name.Builtin"
Ord = "Token.Name.Builtin"
PartialEq = "Token.Name.Builtin"
PartialOrd = "Token.Name.Builtin"
Some = "Token.Name.Builtin"
None = "Token.Name.Builtin"
Ok = "Token.Name.Builtin"
Err = "Token.Name.Builtin"
[Rust.tree_sitter.token_mapping.identifier]
Send = "Token.Name.Builtin"
Sized = "Token.Name.Builtin"
Sync = "Token.Name.Builtin"
Unpin = "Token.Name.Builtin"
Drop = "Token.Name.Builtin"
Fn = "Token.Name.Builtin"
FnMut = "Token.Name.Builtin"
FnOnce = "Token.Name.Builtin"
AsRef = "Token.Name.Builtin"
AsMut = "Token.Name.Builtin"
Into = "Token.Name.Builtin"
From = "Token.Name.Builtin"
Iterator = "Token.Name.Builtin"
Extend = "Token.Name.Builtin"
IntoIterator = "Token.Name.Builtin"
DoubleEndedIterator = "Token.Name.Builtin"
ExactSizeIterator = "Token.Name.Builtin"
Option = "Token.Name.Builtin"
Result = "Token.Name.Builtin"
Box = "Token.Name.Builtin"
ToOwned = "Token.Name.Builtin"
String = "Token.Name.Builtin"
ToString = "Token.Name.Builtin"
Vec = "Token.Name.Builtin"
Clone = "Token.Name.Builtin"
Copy = "Token.Name.Builtin"
Default = "Token.Name.Builtin"
Eq = "Token.Name.Builtin"
Hash = "Token.Name.Builtin"
Ord = "Token.Name.Builtin"
PartialEq = "Token.Name.Builtin"
PartialOrd = "Token.Name.Builtin"
Some = "Token.Name.Builtin"
None = "Token.Name.Builtin"
Ok = "Token.Name.Builtin"
Err = "Token.Name.Builtin"
# these would ideally be covered by primitive_type above but aren't, try "foo: Vec<(i8, i8)>"
u8 = "Token.Keyword"
u16 = "Token.Keyword"
u32 = "Token.Keyword"
u64 = "Token.Keyword"
u128 = "Token.Keyword"
i8 = "Token.Keyword"
i16 = "Token.Keyword"
i32 = "Token.Keyword"
i64 = "Token.Keyword"
i128 = "Token.Keyword"
usize = "Token.Keyword"
isize = "Token.Keyword"
f32 = "Token.Keyword"
f64 = "Token.Keyword"
char = "Token.Keyword"
str = "Token.Keyword"
bool = "Token.Keyword"
